{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025eba7c",
   "metadata": {},
   "source": [
    "# Preprocessing, Windowing and Calendar Features\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/giulatona/iecon2025_tutorial/blob/main/notebooks/02_preprocessing_windowing_features.ipynb)\n",
    "\n",
    "This notebook demonstrates preprocessing techniques for time series forecasting:\n",
    "\n",
    "- **Data Preprocessing**: Cleaning, normalization, and scaling\n",
    "- **Windowing Techniques**: Creating sliding windows for sequence modeling\n",
    "- **Calendar Features**: Adding temporal features (to be used as exogenous features)\n",
    "\n",
    "**Dataset**: UCI Individual Household Electric Power Consumption  \n",
    "**Goal**: Prepare data for machine learning forecasting models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9a4b2",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2fddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f93005",
   "metadata": {},
   "source": [
    "### Dataset Download (Hidden)\n",
    "The following cell downloads the dataset if not available locally. This cell is hidden by default to keep the notebook clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64058aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally...\n",
      "Dataset not found locally. Downloading...\n",
      "Download completed. Extracting...\n",
      "Download completed. Extracting...\n",
      "Extraction completed.\n",
      "Using data file: data/household_power_consumption.txt\n",
      "Extraction completed.\n",
      "Using data file: data/household_power_consumption.txt\n"
     ]
    }
   ],
   "source": [
    "# Download data if not available locally\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Check if running in Google Colab\n",
    "in_colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if in_colab:\n",
    "    print(\"Running in Google Colab - downloading dataset...\")\n",
    "    !wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\n",
    "    !unzip -q household_power_consumption.zip\n",
    "    data_file = 'household_power_consumption.txt'\n",
    "else:\n",
    "    print(\"Running locally...\")\n",
    "    data_file = 'data/household_power_consumption.txt'\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Download dataset if it doesn't exist locally\n",
    "    if not os.path.exists(data_file):\n",
    "        print(\"Dataset not found locally. Downloading...\")\n",
    "        url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip'\n",
    "        zip_file = 'data/household_power_consumption.zip'\n",
    "        \n",
    "        # Download the zip file\n",
    "        urllib.request.urlretrieve(url, zip_file)\n",
    "        print(\"Download completed. Extracting...\")\n",
    "        \n",
    "        # Extract the zip file\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall('data/')\n",
    "        \n",
    "        print(\"Extraction completed.\")\n",
    "    else:\n",
    "        print(\"Dataset found locally.\")\n",
    "\n",
    "print(f\"Using data file: {data_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f8b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (2075259, 9)\n",
      "Date range: 16/12/2006 to 26/11/2010\n",
      "Dataset shape: (2075259, 9)\n",
      "Date range: 16/12/2006 to 26/11/2010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time Global_active_power Global_reactive_power  Voltage  \\\n",
       "0  16/12/2006  17:24:00               4.216                 0.418  234.840   \n",
       "1  16/12/2006  17:25:00               5.360                 0.436  233.630   \n",
       "2  16/12/2006  17:26:00               5.374                 0.498  233.290   \n",
       "3  16/12/2006  17:27:00               5.388                 0.502  233.740   \n",
       "4  16/12/2006  17:28:00               3.666                 0.528  235.680   \n",
       "\n",
       "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
       "0           18.400          0.000          1.000            17.0  \n",
       "1           23.000          0.000          1.000            16.0  \n",
       "2           23.000          0.000          2.000            17.0  \n",
       "3           23.000          0.000          1.000            17.0  \n",
       "4           15.800          0.000          1.000            17.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and perform initial preprocessing\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(data_file, sep=';', low_memory=False)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].iloc[0]} to {df['Date'].iloc[-1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb36ecc",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c714a89",
   "metadata": {},
   "source": [
    "### 1. Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean the household power consumption dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Raw dataset\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned dataset with datetime index\n",
    "    \"\"\"\n",
    "    # TODO: Implement data cleaning\n",
    "    # - Combine Date and Time columns\n",
    "    # - Convert '?' to NaN and handle missing values\n",
    "    # - Convert data types\n",
    "    # - Set datetime index\n",
    "    pass\n",
    "\n",
    "# Apply cleaning\n",
    "# df_clean = clean_data(df)\n",
    "print(\"Data cleaning function defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f4acb",
   "metadata": {},
   "source": [
    "### 2. Data Normalization and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9643db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(df, method='standardize', columns=None):\n",
    "    \"\"\"\n",
    "    Normalize features using different scaling methods.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    method (str): 'standardize', 'minmax', or 'robust'\n",
    "    columns (list): Columns to normalize (None for all numeric)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Normalized dataframe\n",
    "    dict: Scaler parameters for inverse transformation\n",
    "    \"\"\"\n",
    "    # TODO: Implement different normalization methods\n",
    "    # - Standard scaling (z-score)\n",
    "    # - Min-max scaling\n",
    "    # - Robust scaling\n",
    "    # - Return scaler parameters for inverse transformation\n",
    "    pass\n",
    "\n",
    "print(\"Normalization function defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d2c47",
   "metadata": {},
   "source": [
    "## Windowing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56cdfc",
   "metadata": {},
   "source": [
    "### 1. Sliding Window Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(data, window_size, forecast_horizon=1, step_size=1):\n",
    "    \"\"\"\n",
    "    Create sliding windows for time series forecasting.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame or np.array): Time series data\n",
    "    window_size (int): Number of time steps in input window\n",
    "    forecast_horizon (int): Number of time steps to predict\n",
    "    step_size (int): Step size between windows\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (X, y) arrays for model training\n",
    "    \"\"\"\n",
    "    # TODO: Implement sliding window creation\n",
    "    # - Create input sequences (X) and target sequences (y)\n",
    "    # - Handle multiple forecast horizons\n",
    "    # - Support different step sizes\n",
    "    # - Preserve temporal order\n",
    "    pass\n",
    "\n",
    "print(\"Sliding window function defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c03b30",
   "metadata": {},
   "source": [
    "## Calendar Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1b7eb",
   "metadata": {},
   "source": [
    "### 1. Basic Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad784ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temporal_features(df, datetime_col=None):\n",
    "    \"\"\"\n",
    "    Extract basic temporal features from datetime index or column.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    datetime_col (str): Name of datetime column (None if using index)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with added temporal features\n",
    "    \"\"\"\n",
    "    # TODO: Implement temporal feature extraction\n",
    "    # - Hour, day, month, year\n",
    "    # - Day of week, day of year\n",
    "    # - Quarter, week of year\n",
    "    # - Is weekend, is holiday\n",
    "    pass\n",
    "\n",
    "print(\"Temporal features function defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f244f1db",
   "metadata": {},
   "source": [
    "### 2. Cyclical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cyclical_features(df, columns):\n",
    "    \"\"\"\n",
    "    Create cyclical encoding for temporal features using sine and cosine.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    columns (dict): Dictionary mapping column names to their periods\n",
    "                   e.g., {'hour': 24, 'day_of_week': 7, 'month': 12}\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with cyclical features\n",
    "    \"\"\"\n",
    "    # TODO: Implement cyclical encoding\n",
    "    # - Apply sine and cosine transformations\n",
    "    # - Handle different periods (hour, day, week, month)\n",
    "    # - Preserve cyclical nature of time\n",
    "    pass\n",
    "\n",
    "def visualize_cyclical_features(df, feature_name, period):\n",
    "    \"\"\"\n",
    "    Visualize cyclical features to verify encoding.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Dataframe with cyclical features\n",
    "    feature_name (str): Name of the original feature\n",
    "    period (int): Period of the cyclical feature\n",
    "    \"\"\"\n",
    "    # TODO: Implement visualization\n",
    "    # - Plot original vs cyclical features\n",
    "    # - Show circular representation\n",
    "    # - Validate encoding correctness\n",
    "    pass\n",
    "\n",
    "print(\"Cyclical encoding functions defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183eba97",
   "metadata": {},
   "source": [
    "### 3. Holiday and Special Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_holiday_features(df, country='France'):\n",
    "    \"\"\"\n",
    "    Add holiday indicators and special events.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe with datetime index\n",
    "    country (str): Country for holiday calendar\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with holiday features\n",
    "    \"\"\"\n",
    "    # TODO: Implement holiday features\n",
    "    # - Use holidays library for country-specific holidays\n",
    "    # - Add binary indicators for holidays\n",
    "    # - Include special events (vacation periods, etc.)\n",
    "    # - Add days before/after holidays\n",
    "    pass\n",
    "\n",
    "print(\"Holiday features function defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dfa8b0",
   "metadata": {},
   "source": [
    "## Lag Features and Rolling Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ede3e",
   "metadata": {},
   "source": [
    "### 1. Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(df, columns, lags):\n",
    "    \"\"\"\n",
    "    Create lag features for specified columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    columns (list): Columns to create lags for\n",
    "    lags (list): List of lag periods\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with lag features\n",
    "    \"\"\"\n",
    "    # TODO: Implement lag feature creation\n",
    "    # - Create lagged versions of specified columns\n",
    "    # - Handle multiple lag periods\n",
    "    # - Manage missing values from lagging\n",
    "    pass\n",
    "\n",
    "print(\"Lag features function defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd816689",
   "metadata": {},
   "source": [
    "### 2. Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0bbef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_features(df, columns, windows, statistics=['mean', 'std', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Create rolling window statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    columns (list): Columns to calculate statistics for\n",
    "    windows (list): List of window sizes\n",
    "    statistics (list): List of statistics to calculate\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with rolling features\n",
    "    \"\"\"\n",
    "    # TODO: Implement rolling statistics\n",
    "    # - Calculate rolling mean, std, min, max\n",
    "    # - Support multiple window sizes\n",
    "    # - Add rolling quantiles\n",
    "    # - Handle edge cases\n",
    "    pass\n",
    "\n",
    "def create_expanding_features(df, columns, statistics=['mean', 'std']):\n",
    "    \"\"\"\n",
    "    Create expanding window statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    columns (list): Columns to calculate statistics for\n",
    "    statistics (list): List of statistics to calculate\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with expanding features\n",
    "    \"\"\"\n",
    "    # TODO: Implement expanding statistics\n",
    "    # - Calculate expanding mean, std\n",
    "    # - Useful for trend analysis\n",
    "    pass\n",
    "\n",
    "print(\"Rolling statistics functions defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddcf5b",
   "metadata": {},
   "source": [
    "## Complete Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesPreprocessor:\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for time series forecasting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size=24, forecast_horizon=1, \n",
    "                 normalization='standardize', add_cyclical=True):\n",
    "        \"\"\"\n",
    "        Initialize preprocessing pipeline.\n",
    "        \n",
    "        Parameters:\n",
    "        window_size (int): Input sequence length\n",
    "        forecast_horizon (int): Number of steps to predict\n",
    "        normalization (str): Normalization method\n",
    "        add_cyclical (bool): Whether to add cyclical features\n",
    "        \"\"\"\n",
    "        # TODO: Initialize pipeline components\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        Fit preprocessing pipeline on training data.\n",
    "        \n",
    "        Parameters:\n",
    "        df (pd.DataFrame): Training dataset\n",
    "        \n",
    "        Returns:\n",
    "        self: Fitted preprocessor\n",
    "        \"\"\"\n",
    "        # TODO: Fit all preprocessing steps\n",
    "        pass\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Transform dataset using fitted pipeline.\n",
    "        \n",
    "        Parameters:\n",
    "        df (pd.DataFrame): Input dataset\n",
    "        \n",
    "        Returns:\n",
    "        tuple: (X, y) for model training/prediction\n",
    "        \"\"\"\n",
    "        # TODO: Apply all preprocessing steps\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"\n",
    "        Fit and transform in one step.\n",
    "        \n",
    "        Parameters:\n",
    "        df (pd.DataFrame): Input dataset\n",
    "        \n",
    "        Returns:\n",
    "        tuple: (X, y) for model training\n",
    "        \"\"\"\n",
    "        return self.fit(df).transform(df)\n",
    "    \n",
    "    def inverse_transform(self, predictions):\n",
    "        \"\"\"\n",
    "        Inverse transform predictions to original scale.\n",
    "        \n",
    "        Parameters:\n",
    "        predictions (np.array): Model predictions\n",
    "        \n",
    "        Returns:\n",
    "        np.array: Predictions in original scale\n",
    "        \"\"\"\n",
    "        # TODO: Implement inverse transformation\n",
    "        pass\n",
    "\n",
    "print(\"TimeSeriesPreprocessor class defined. Implementation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954bf15",
   "metadata": {},
   "source": [
    "## Usage Examples and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add example usage of the preprocessing pipeline\n",
    "# Example:\n",
    "# preprocessor = TimeSeriesPreprocessor(window_size=24, forecast_horizon=1)\n",
    "# X_train, y_train = preprocessor.fit_transform(df_train)\n",
    "# X_test, y_test = preprocessor.transform(df_test)\n",
    "\n",
    "print(\"Usage examples to be implemented.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e4e62",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive framework for time series preprocessing including:\n",
    "\n",
    "### Key Components:\n",
    "1. **Data Cleaning**: Handling missing values, data type conversion, datetime processing\n",
    "2. **Normalization**: Multiple scaling methods for different use cases\n",
    "3. **Windowing**: Sliding windows, overlapping sequences, multi-horizon support\n",
    "4. **Calendar Features**: Temporal features, cyclical encoding, holiday indicators\n",
    "5. **Lag Features**: Historical values and rolling statistics\n",
    "6. **Pipeline**: Complete preprocessing class for reproducible workflows\n",
    "\n",
    "### Next Steps:\n",
    "- Implement the defined functions with specific logic\n",
    "- Test with the household power consumption dataset\n",
    "- Validate preprocessing quality\n",
    "- Integrate with machine learning models\n",
    "\n",
    "### Best Practices:\n",
    "- Always preserve temporal order in time series data\n",
    "- Avoid data leakage when creating features\n",
    "- Use separate train/validation/test splits for time series\n",
    "- Validate all transformations are invertible\n",
    "- Document all preprocessing steps for reproducibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iecon2025-tutorial-z-J6dBct-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
